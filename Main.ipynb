{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondAssignment-Version2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTkExqIZcsMA",
        "colab_type": "text"
      },
      "source": [
        "# Library import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRKxfcZscv4T",
        "colab_type": "code",
        "outputId": "aa57b972-7a78-4afc-baab-a5def953878e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Essentials packages\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random as rn\n",
        "\n",
        "# Model selection - Split data to train set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Keras Deep learning - Create neuro network model\n",
        "from keras.models import Sequential\n",
        "import keras.layers as layers\n",
        "\n",
        "# Image processing tools for elastic distortion\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lt5x5f9xdQfd",
        "colab_type": "text"
      },
      "source": [
        "# Dataset import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnrRl2Cos-ww",
        "colab_type": "text"
      },
      "source": [
        "In this step, we import the Semeion dataset from our github repository - This is the same file found on UCI repository.\n",
        "\n",
        "The dataset is also splitted in to train and test data with 80:20 split rule (80% data is for training, 20% is for testing). Here we use stratification to assure that the proportions of each digit classes in test and train sets are the similar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el50S0Sgdd5X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open dataset\n",
        "digits_url = \"https://raw.githubusercontent.com/trangnguyenanhthuan/MachineLearningAsm2/master/semeion.data\" # You can replace this line with local file's path if necessary\n",
        "digits = pd.read_csv(digits_url, delimiter = \" \", header = None)\n",
        "digits.drop(columns=[266], inplace= True)\n",
        "label_cols = [i + 256 for i in range (10)]\n",
        "\n",
        "# Define X and Y\n",
        "X = digits.drop(columns = label_cols)\n",
        "Y = digits[label_cols]\n",
        "\n",
        "# Split test and train\n",
        "index,labels = np.where(Y.values == 1) # Stratification to make sure the each class has similar number of examples\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, stratify = labels, test_size=0.2, random_state=0) # Use a fixed random state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enjgmIBvdJY_",
        "colab_type": "text"
      },
      "source": [
        "# Base model: K Nearest Neighbor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOdcdKcXtw6W",
        "colab_type": "text"
      },
      "source": [
        "The base model is KNN model. Here, we use set the number of neighbors to 3 as it results in highest test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoFRa5BKdPYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import KNN \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create KNN Model with n_neighbor equals to 3\n",
        "class KNNModel:\n",
        "  def __init__(self):\n",
        "    self.model = KNeighborsClassifier(n_neighbors=3)\n",
        "  def fit(self, X_train, Y_train):\n",
        "    self.model.fit(X_train, Y_train)\n",
        "  def predict(self, X_predict):\n",
        "    return self.model.predict(X_predict)\n",
        "  def accuracy(self, X_test, Y_test):\n",
        "    return self.model.score(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYcFDCIyedPN",
        "colab_type": "code",
        "outputId": "41268287-a633-410d-91d3-bb9ddf12a9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Create KNN model\n",
        "knn_model = KNNModel()\n",
        "knn_model.fit(X_train, Y_train)\n",
        "\n",
        "# View performance\n",
        "knn_score = knn_model.accuracy(X_test, Y_test)\n",
        "print(f\"The accuracy for KNN Model is: {knn_score}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for KNN Model is: 0.9059561128526645\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2V41nwFVfB8F",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KUX2PaJt-BA",
        "colab_type": "text"
      },
      "source": [
        "Support Vector Machine is an algorithm to find a hyperplane which \"best\" seperate the training examples into their classes. It is arguably considered the most efficient out-of-the-box classifying algorithm by many. \n",
        "\n",
        "Here, the regularization constant is chosen to be 5 as its results in high test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM1XVVMAfJ0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Support vector machine\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create SVM with C = 5 - C is the strength of the regularization\n",
        "class SVCModel:\n",
        "  def __init__(self):\n",
        "    self.model = SVC(C=5)\n",
        "  def fit(self, X_train, Y_train):\n",
        "    self.model.fit(X_train, Y_train)\n",
        "  def predict(self, X_predict):\n",
        "    return self.model.predict(X_predict)\n",
        "  def accuracy(self, X_test, Y_test):\n",
        "    return self.model.score(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X50EpK8qfoWH",
        "colab_type": "code",
        "outputId": "3fe76e08-c944-4f69-b281-7413960ffaa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Get np array instead of dataframe\n",
        "svc_X_train = X_train.values\n",
        "svc_X_test = X_test.values\n",
        "\n",
        "# Instead of using a dummy array -> We use label\n",
        "svc_Y_test = np.argmax(Y_test.values, axis=1)\n",
        "svc_Y_train = np.argmax(Y_train.values, axis=1)\n",
        "\n",
        "# Fit\n",
        "svc_model = SVCModel()\n",
        "svc_model.fit(svc_X_train, svc_Y_train)\n",
        "\n",
        "# Score\n",
        "svc_score = svc_model.accuracy(svc_X_test, svc_Y_test)\n",
        "print(f\"The accuracy for SVC Model is {svc_score}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy for SVC Model is 0.9686520376175548\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LF4dJ-8zR8iV",
        "colab_type": "text"
      },
      "source": [
        "## Linear Regression Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeWMO4OESHbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Create Linear Regression Classification\n",
        "class LRC:\n",
        "  def predict_based(self,X_train,y_train,y):\n",
        "      # Divide X_train by classes\n",
        "      X_divided_by_class = []\n",
        "      for i in range(10):\n",
        "          X_divided_by_class.append(X_train[y_train == i].T)\n",
        "      y_pre = []\n",
        "      \n",
        "      # Calculate y_hat\n",
        "      for i in range(10):\n",
        "          y_pre.append(LinearRegression().fit(X_divided_by_class[i],y).predict(X_divided_by_class[i]))\n",
        "      \n",
        "      # Deicide label based on the minimum distance\n",
        "      label = np.zeros(10)\n",
        "      for i in range(10):\n",
        "          label[i] = np.sum(np.square(y - y_pre[i]))\n",
        "      return np.argmin(label)\n",
        "\n",
        "  def predict(self,X_train,y_train,Y):\n",
        "      y_pre = []\n",
        "      for i in range(len(Y)):\n",
        "        y_pre.append(self.predict_based(X_train,y_train,Y.iloc[i].T))\n",
        "      return y_pre"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhEzpGYcSNr5",
        "colab_type": "code",
        "outputId": "d7296ed1-98dd-441b-9c8f-2ccf383dd920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Train model and print the accuracy (model achieve best result when test_size = 0.5)\n",
        "lrc_X_train, lrc_X_test, lrc_Y_train, lrc_Y_test = train_test_split(X, labels,test_size = 0.2, stratify = labels, random_state = 0)\n",
        "lrc_Y_predicted = LRC().predict(lrc_X_train, lrc_Y_train, lrc_X_test)\n",
        "\n",
        "print(\"The accuracy of the Linear Regression Classification model:\",accuracy_score(lrc_Y_test, lrc_Y_predicted))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the Linear Regression Classification model: 0.9310344827586207\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohM4Cqn7gfXG",
        "colab_type": "text"
      },
      "source": [
        "# LeNet-5 Based Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdusSREUSepb",
        "colab_type": "text"
      },
      "source": [
        "![LeNet 5 architecture](https://miro.medium.com/max/1400/1*yG2c7PQQCRG0gL6ncfoQCg.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTa9qM7wwLHB",
        "colab_type": "text"
      },
      "source": [
        "The architecture of this convolutional neural network is inspired by the approach taken by Yann LeCun for creating his LeNet-5 network. \n",
        "\n",
        "For the small dataset, we added the dropout layers with probability 0.3 after the max pooling layers to alleviate the effects of overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxMcCD3JgiEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create neuro network model with LeNet 5 architecture\n",
        "class LeNet5:\n",
        "  def __init__(self):\n",
        "    # Create CNN Model\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolution -> Average Pooling\n",
        "    model.add(layers.Conv2D(filters=6, kernel_size=(5, 5), activation='relu', input_shape=(32,32,1)))\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Convolution -> Average Pooling\n",
        "    model.add(layers.Conv2D(filters=16, kernel_size=(5, 5), activation='relu'))\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    # Flatten into array\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # First dense layer\n",
        "    model.add(layers.Dense(units=120, activation='relu'))\n",
        "\n",
        "    # Second dense layer\n",
        "    model.add(layers.Dense(units=84, activation='relu'))\n",
        "\n",
        "    # Result layer\n",
        "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=\"adam\", metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
        "\n",
        "    # Assign to instance\n",
        "    self.model = model\n",
        "\n",
        "  def fit(self, X_train, Y_train, epochs=150, batch_size=5):\n",
        "      self.model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size)\n",
        "\n",
        "  def predict(self, X_predict):\n",
        "    return self.model.predict(X_predict)\n",
        "\n",
        "  def accuracy(self, X_test, Y_test):\n",
        "    _, accuracy = self.model.evaluate(X_test, Y_test)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NDo_ybdkbqe",
        "colab_type": "text"
      },
      "source": [
        "## a) Without elastic distortion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQkJ-RWchvE_",
        "colab_type": "code",
        "outputId": "169acdb2-d8e4-48e9-8ce6-360ae01c8618",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Make sure that we add the chanel layer, in this case 1\n",
        "lenet_X_train = X_train.values.reshape([-1, 16, 16, 1])\n",
        "lenet_X_test = X_test.values.reshape([-1, 16, 16, 1])\n",
        "\n",
        "# Add padding to create a (32, 32, 1) image\n",
        "lenet_X_train = np.pad(lenet_X_train, ((0, 0), (8, 8), (8, 8), (0, 0)))\n",
        "lenet_X_test = np.pad(lenet_X_test, ((0, 0), (8, 8), (8, 8), (0, 0)))\n",
        "\n",
        "# Fit\n",
        "lenet_model = LeNet5()\n",
        "lenet_model.fit(lenet_X_train, Y_train, epochs=150, batch_size=5)\n",
        "\n",
        "# Score\n",
        "score = lenet_model.accuracy(lenet_X_test, Y_test)\n",
        "print(f\"The accuracy of the LeNet5 model (without elastic distortion) is {score}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "1274/1274 [==============================] - 2s 1ms/step - loss: 1.4181 - accuracy: 0.5031\n",
            "Epoch 2/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.4735 - accuracy: 0.8540\n",
            "Epoch 3/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.3031 - accuracy: 0.9027\n",
            "Epoch 4/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.2399 - accuracy: 0.9231\n",
            "Epoch 5/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.2137 - accuracy: 0.9270\n",
            "Epoch 6/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.1849 - accuracy: 0.9380\n",
            "Epoch 7/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.1663 - accuracy: 0.9490\n",
            "Epoch 8/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.1392 - accuracy: 0.9521\n",
            "Epoch 9/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.1150 - accuracy: 0.9560\n",
            "Epoch 10/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0928 - accuracy: 0.9717\n",
            "Epoch 11/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.1034 - accuracy: 0.9615\n",
            "Epoch 12/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0973 - accuracy: 0.9662\n",
            "Epoch 13/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0909 - accuracy: 0.9678\n",
            "Epoch 14/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0849 - accuracy: 0.9757\n",
            "Epoch 15/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0662 - accuracy: 0.9812\n",
            "Epoch 16/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0725 - accuracy: 0.9812\n",
            "Epoch 17/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0632 - accuracy: 0.9788\n",
            "Epoch 18/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0635 - accuracy: 0.9757\n",
            "Epoch 19/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0637 - accuracy: 0.9796\n",
            "Epoch 20/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0493 - accuracy: 0.9843\n",
            "Epoch 21/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0530 - accuracy: 0.9804\n",
            "Epoch 22/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0624 - accuracy: 0.9772\n",
            "Epoch 23/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0333 - accuracy: 0.9898\n",
            "Epoch 24/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0476 - accuracy: 0.9843\n",
            "Epoch 25/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0449 - accuracy: 0.9859\n",
            "Epoch 26/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0682 - accuracy: 0.9804\n",
            "Epoch 27/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0538 - accuracy: 0.9804\n",
            "Epoch 28/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0671 - accuracy: 0.9780\n",
            "Epoch 29/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0387 - accuracy: 0.9827\n",
            "Epoch 30/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0383 - accuracy: 0.9851\n",
            "Epoch 31/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0502 - accuracy: 0.9827\n",
            "Epoch 32/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0359 - accuracy: 0.9898\n",
            "Epoch 33/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0291 - accuracy: 0.9929\n",
            "Epoch 34/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0482 - accuracy: 0.9859\n",
            "Epoch 35/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0507 - accuracy: 0.9835\n",
            "Epoch 36/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0343 - accuracy: 0.9882\n",
            "Epoch 37/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0489 - accuracy: 0.9867\n",
            "Epoch 38/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0380 - accuracy: 0.9867\n",
            "Epoch 39/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0372 - accuracy: 0.9882\n",
            "Epoch 40/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0275 - accuracy: 0.9922\n",
            "Epoch 41/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0398 - accuracy: 0.9874\n",
            "Epoch 42/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0361 - accuracy: 0.9906\n",
            "Epoch 43/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0353 - accuracy: 0.9890\n",
            "Epoch 44/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0195 - accuracy: 0.9929\n",
            "Epoch 45/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0291 - accuracy: 0.9906\n",
            "Epoch 46/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0325 - accuracy: 0.9874\n",
            "Epoch 47/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0294 - accuracy: 0.9922\n",
            "Epoch 48/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0305 - accuracy: 0.9890\n",
            "Epoch 49/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0386 - accuracy: 0.9827\n",
            "Epoch 50/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0801 - accuracy: 0.9741\n",
            "Epoch 51/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0420 - accuracy: 0.9867\n",
            "Epoch 52/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0122 - accuracy: 0.9976\n",
            "Epoch 53/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9914\n",
            "Epoch 54/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0416 - accuracy: 0.9867\n",
            "Epoch 55/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0292 - accuracy: 0.9953\n",
            "Epoch 56/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0508 - accuracy: 0.9827\n",
            "Epoch 57/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0309 - accuracy: 0.9914\n",
            "Epoch 58/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0360 - accuracy: 0.9890\n",
            "Epoch 59/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0291 - accuracy: 0.9906\n",
            "Epoch 60/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0167 - accuracy: 0.9953\n",
            "Epoch 61/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0233 - accuracy: 0.9953\n",
            "Epoch 62/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0169 - accuracy: 0.9906\n",
            "Epoch 63/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0253 - accuracy: 0.9922\n",
            "Epoch 64/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0298 - accuracy: 0.9906\n",
            "Epoch 65/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0337 - accuracy: 0.9890\n",
            "Epoch 66/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0246 - accuracy: 0.9882\n",
            "Epoch 67/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0261 - accuracy: 0.9929\n",
            "Epoch 68/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0405 - accuracy: 0.9890\n",
            "Epoch 69/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0255 - accuracy: 0.9914\n",
            "Epoch 70/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0178 - accuracy: 0.9945\n",
            "Epoch 71/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0274 - accuracy: 0.9898\n",
            "Epoch 72/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0328 - accuracy: 0.9906\n",
            "Epoch 73/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9914\n",
            "Epoch 74/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0205 - accuracy: 0.9929\n",
            "Epoch 75/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0214 - accuracy: 0.9898\n",
            "Epoch 76/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0210 - accuracy: 0.9929\n",
            "Epoch 77/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9969\n",
            "Epoch 78/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0393 - accuracy: 0.9882\n",
            "Epoch 79/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0325 - accuracy: 0.9859\n",
            "Epoch 80/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0237 - accuracy: 0.9929\n",
            "Epoch 81/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0179 - accuracy: 0.9945\n",
            "Epoch 82/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9914\n",
            "Epoch 83/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9945\n",
            "Epoch 84/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0189 - accuracy: 0.9945\n",
            "Epoch 85/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0240 - accuracy: 0.9953\n",
            "Epoch 86/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0152 - accuracy: 0.9961\n",
            "Epoch 87/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0235 - accuracy: 0.9929\n",
            "Epoch 88/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0284 - accuracy: 0.9929\n",
            "Epoch 89/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0276 - accuracy: 0.9890\n",
            "Epoch 90/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0257 - accuracy: 0.9922\n",
            "Epoch 91/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0230 - accuracy: 0.9906\n",
            "Epoch 92/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0195 - accuracy: 0.9929\n",
            "Epoch 93/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0357 - accuracy: 0.9898\n",
            "Epoch 94/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0220 - accuracy: 0.9898\n",
            "Epoch 95/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0182 - accuracy: 0.9929\n",
            "Epoch 96/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0090 - accuracy: 0.9969\n",
            "Epoch 97/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0100 - accuracy: 0.9984\n",
            "Epoch 98/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9922\n",
            "Epoch 99/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0132 - accuracy: 0.9937\n",
            "Epoch 100/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0576 - accuracy: 0.9867\n",
            "Epoch 101/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0398 - accuracy: 0.9890\n",
            "Epoch 102/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0103 - accuracy: 0.9961\n",
            "Epoch 103/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.9961\n",
            "Epoch 104/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9969\n",
            "Epoch 105/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0115 - accuracy: 0.9961\n",
            "Epoch 106/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0220 - accuracy: 0.9906\n",
            "Epoch 107/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0260 - accuracy: 0.9922\n",
            "Epoch 108/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0123 - accuracy: 0.9945\n",
            "Epoch 109/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0288 - accuracy: 0.9914\n",
            "Epoch 110/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9961\n",
            "Epoch 111/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0191 - accuracy: 0.9945\n",
            "Epoch 112/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0216 - accuracy: 0.9914\n",
            "Epoch 113/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0184 - accuracy: 0.9953\n",
            "Epoch 114/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0172 - accuracy: 0.9953\n",
            "Epoch 115/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0132 - accuracy: 0.9929\n",
            "Epoch 116/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0079 - accuracy: 0.9961\n",
            "Epoch 117/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0083 - accuracy: 0.9984\n",
            "Epoch 118/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0267 - accuracy: 0.9929\n",
            "Epoch 119/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0146 - accuracy: 0.9945\n",
            "Epoch 120/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0159 - accuracy: 0.9945\n",
            "Epoch 121/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0091 - accuracy: 0.9945\n",
            "Epoch 122/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.9969\n",
            "Epoch 123/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9945\n",
            "Epoch 124/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0317 - accuracy: 0.9945\n",
            "Epoch 125/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0411 - accuracy: 0.9929\n",
            "Epoch 126/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0193 - accuracy: 0.9969\n",
            "Epoch 127/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0175 - accuracy: 0.9929\n",
            "Epoch 128/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0299 - accuracy: 0.9906\n",
            "Epoch 129/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0151 - accuracy: 0.9969\n",
            "Epoch 130/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0050 - accuracy: 0.9984\n",
            "Epoch 131/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0284 - accuracy: 0.9922\n",
            "Epoch 132/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0271 - accuracy: 0.9937\n",
            "Epoch 133/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0196 - accuracy: 0.9922\n",
            "Epoch 134/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0340 - accuracy: 0.9914\n",
            "Epoch 135/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0248 - accuracy: 0.9929\n",
            "Epoch 136/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0037 - accuracy: 0.9984\n",
            "Epoch 137/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0079 - accuracy: 0.9969\n",
            "Epoch 138/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0107 - accuracy: 0.9976\n",
            "Epoch 139/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0220 - accuracy: 0.9945\n",
            "Epoch 140/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9937\n",
            "Epoch 141/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0281 - accuracy: 0.9929\n",
            "Epoch 142/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0144 - accuracy: 0.9953\n",
            "Epoch 143/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0371 - accuracy: 0.9922\n",
            "Epoch 144/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0066 - accuracy: 0.9984\n",
            "Epoch 145/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0124 - accuracy: 0.9953\n",
            "Epoch 146/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0246 - accuracy: 0.9937\n",
            "Epoch 147/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0233 - accuracy: 0.9929\n",
            "Epoch 148/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0154 - accuracy: 0.9929\n",
            "Epoch 149/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0231 - accuracy: 0.9937\n",
            "Epoch 150/150\n",
            "1274/1274 [==============================] - 1s 1ms/step - loss: 0.0106 - accuracy: 0.9969\n",
            "319/319 [==============================] - 0s 392us/step\n",
            "The accuracy of the LeNet5 model (without elastic distortion) is 0.9811912178993225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZHnJiWVkfMI",
        "colab_type": "text"
      },
      "source": [
        "## b) With Elastic Distortion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43RqRsXGxnwX",
        "colab_type": "text"
      },
      "source": [
        "One of the common data augmentation method for CNN is affine distortion and elastic distortion. The latter was proposed by Simard in his influencial paper in 2003.  Here, the elastic_transform function is implemented based on his research to generate more training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6hXdxmDkiFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def elastic_transform(image, alpha, sigma, random_state=None):\n",
        "    \"\"\"\n",
        "    Elastic Distortion function implemented based on Simard's paper\n",
        "    image: the image that requires distortion\n",
        "    alpha: the 'strength' of the distortion\n",
        "    sigma: the standard deviation of the Gaussian Convolutional Filter\n",
        "    \"\"\"\n",
        "    if random_state is None:\n",
        "        random_state = np.random.RandomState(None)\n",
        "\n",
        "    image_shape = image.shape\n",
        "    dx = alpha * gaussian_filter((random_state.rand(*image_shape) * 2 - 1), sigma, mode=\"constant\", cval=0)\n",
        "    dy = alpha * gaussian_filter((random_state.rand(*image_shape) * 2 - 1), sigma, mode=\"constant\", cval=0)\n",
        "    dz = np.zeros(dx.shape)\n",
        "\n",
        "    x, y, z = np.meshgrid(np.arange(image_shape[0]), np.arange(image_shape[1]), np.arange(image_shape[2]))\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
        "\n",
        "    distored_image = map_coordinates(image, indices, order=1, mode='reflect')\n",
        "    return distored_image.reshape(image_shape)\n",
        "\n",
        "def generate_elastic_distortion(images, classes, alpha, sigma, image_width = 16, image_height = 16, per_image=5):\n",
        "    \"\"\"\n",
        "    Function to create bulk agmentation\n",
        "    Parameters:\n",
        "    - images: An array with the shape of (number_of_images, image_width x image_height)\n",
        "    - image_width: The width of each image\n",
        "    - alpha: The degree (magnitude) of transformation\n",
        "    - sigma: The standard deviation of the Convolution Gaussian kernel\n",
        "    - image_height: The height of each image\n",
        "    - per_image: How many disorted image to generate for each image\n",
        "    \"\"\"\n",
        "    # Intialize an array\n",
        "    new_dataset = np.zeros([1, 266])\n",
        "    \n",
        "    # Generate elastic distorion for images\n",
        "    for i in range(images.shape[0]):\n",
        "        # Image now has the shape (image_width x image_height) -> Reshape\n",
        "        image = images[i, :].reshape([image_width, image_height, 1]) # The number of channel is 1\n",
        "        result = classes[i, :]\n",
        "\n",
        "        for _ in range(per_image):\n",
        "            # Generate distorted image using elastic_transform\n",
        "            distorted_image = elastic_transform(image, alpha, sigma)\n",
        "            distorted_image = distorted_image.reshape([image_width * image_height])\n",
        "            combined = np.concatenate((distorted_image, result))\n",
        "            \n",
        "            # Push to array\n",
        "            new_dataset = np.append(new_dataset, combined.reshape(1, -1), axis=0)\n",
        "\n",
        "    return np.delete(new_dataset, 0, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOsIiVEmmRPf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate Elastic Distortion of images\n",
        "# We generate 3 new distorted images per original image and then create a new dataset\n",
        "new_dataset = generate_elastic_distortion(X_train.values, Y_train.values, alpha=300, sigma=4, per_image=3)\n",
        "lenet_X_train = new_dataset[:, :256]\n",
        "lenet_Y_train = new_dataset[:, 256:]\n",
        "\n",
        "# Make sure that we add the chanel layer, in this case 1\n",
        "lenet_X_train = lenet_X_train.reshape([-1, 16, 16, 1])\n",
        "lenet_X_test = X_test.values.reshape([-1, 16, 16, 1])\n",
        "\n",
        "# Add padding to create a (32, 32, 1) image\n",
        "lenet_X_train = np.pad(lenet_X_train, ((0, 0), (8, 8), (8, 8), (0, 0)))\n",
        "lenet_X_test = np.pad(lenet_X_test, ((0, 0), (8, 8), (8, 8), (0, 0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYXbQf8jyH0J",
        "colab_type": "text"
      },
      "source": [
        "We then train the LeNet model on these newly generated data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-ITYPn7nDA8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "21dbd3c7-418a-452f-8ae4-8b395562f699"
      },
      "source": [
        "# Fit\n",
        "lenet_model = LeNet5()\n",
        "lenet_model.fit(lenet_X_train, lenet_Y_train, epochs=50, batch_size=5)\n",
        "\n",
        "# Score\n",
        "score = lenet_model.accuracy(lenet_X_test, Y_test)\n",
        "print(f\"The score of the LeNet5 model (with elastic distortion) is {score}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 1.0562 - accuracy: 0.6418\n",
            "Epoch 2/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.4631 - accuracy: 0.8443\n",
            "Epoch 3/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.3690 - accuracy: 0.8731\n",
            "Epoch 4/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.3264 - accuracy: 0.8906\n",
            "Epoch 5/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.2759 - accuracy: 0.9076\n",
            "Epoch 6/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.2609 - accuracy: 0.9079\n",
            "Epoch 7/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.2309 - accuracy: 0.9283\n",
            "Epoch 8/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.2012 - accuracy: 0.9351\n",
            "Epoch 9/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1892 - accuracy: 0.9401\n",
            "Epoch 10/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1829 - accuracy: 0.9375\n",
            "Epoch 11/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1823 - accuracy: 0.9369\n",
            "Epoch 12/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1481 - accuracy: 0.9490\n",
            "Epoch 13/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1473 - accuracy: 0.9482\n",
            "Epoch 14/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1339 - accuracy: 0.9508\n",
            "Epoch 15/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1463 - accuracy: 0.9477\n",
            "Epoch 16/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1312 - accuracy: 0.9584\n",
            "Epoch 17/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1210 - accuracy: 0.9602\n",
            "Epoch 18/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1100 - accuracy: 0.9608\n",
            "Epoch 19/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1206 - accuracy: 0.9602\n",
            "Epoch 20/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1022 - accuracy: 0.9626\n",
            "Epoch 21/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1033 - accuracy: 0.9644\n",
            "Epoch 22/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1016 - accuracy: 0.9657\n",
            "Epoch 23/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0886 - accuracy: 0.9678\n",
            "Epoch 24/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.1112 - accuracy: 0.9626\n",
            "Epoch 25/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0967 - accuracy: 0.9673\n",
            "Epoch 26/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0924 - accuracy: 0.9662\n",
            "Epoch 27/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0855 - accuracy: 0.9683\n",
            "Epoch 28/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0951 - accuracy: 0.9717\n",
            "Epoch 29/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0832 - accuracy: 0.9717\n",
            "Epoch 30/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0739 - accuracy: 0.9741\n",
            "Epoch 31/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0721 - accuracy: 0.9738\n",
            "Epoch 32/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0748 - accuracy: 0.9751\n",
            "Epoch 33/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0659 - accuracy: 0.9791\n",
            "Epoch 34/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0748 - accuracy: 0.9744\n",
            "Epoch 35/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0652 - accuracy: 0.9762\n",
            "Epoch 36/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0659 - accuracy: 0.9751\n",
            "Epoch 37/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0595 - accuracy: 0.9801\n",
            "Epoch 38/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0701 - accuracy: 0.9762\n",
            "Epoch 39/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0719 - accuracy: 0.9793\n",
            "Epoch 40/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0721 - accuracy: 0.9778\n",
            "Epoch 41/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0592 - accuracy: 0.9788\n",
            "Epoch 42/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0756 - accuracy: 0.9780\n",
            "Epoch 43/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0694 - accuracy: 0.9791\n",
            "Epoch 44/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0679 - accuracy: 0.9759\n",
            "Epoch 45/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0692 - accuracy: 0.9780\n",
            "Epoch 46/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0632 - accuracy: 0.9765\n",
            "Epoch 47/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0640 - accuracy: 0.9775\n",
            "Epoch 48/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0611 - accuracy: 0.9819\n",
            "Epoch 49/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0600 - accuracy: 0.9796\n",
            "Epoch 50/50\n",
            "3822/3822 [==============================] - 4s 1ms/step - loss: 0.0560 - accuracy: 0.9801\n",
            "319/319 [==============================] - 0s 341us/step\n",
            "The score of the LeNet5 model (with elastic distortion) is 0.9780564308166504\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3WccoXAji9R",
        "colab_type": "text"
      },
      "source": [
        "# Hybrid Convolutional Neural Network With SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez1kIJtUW1z2",
        "colab_type": "text"
      },
      "source": [
        "![Hybrid Convolutional Neural Network With SVM](https://raw.githubusercontent.com/trangnguyenanhthuan/MachineLearningAsm2/master/img.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry-BBU8Qyv-L",
        "colab_type": "text"
      },
      "source": [
        "Bellow is the implementation of a modified hybrid CNN-SVM model. While the CNN uses the training data for feature extraction, the SVM then makes use of these extracted features to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibxTzVYUjrEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import Model to extract features from keras model\n",
        "from keras.models import Model\n",
        "# Import SVC to classify extracted features\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# Create neuro network model with Hybrid Convolutional Neural Network With SVM - we add Dropout layers\n",
        "class HybridSVM:\n",
        "  def __init__(self):\n",
        "    # Initialize a neural network for feature extraction\n",
        "    model = Sequential()\n",
        "\n",
        "    # Convolution -> Average Pooling\n",
        "    model.add(layers.Conv2D(filters=25, kernel_size=(5, 5), activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "    \n",
        "    # Convolution -> Average Pooling\n",
        "    model.add(layers.Conv2D(filters=50, kernel_size=(5, 5), activation='relu', input_shape=(28,28,1)))\n",
        "    model.add(layers.MaxPooling2D())\n",
        "    model.add(layers.Dropout(0.5))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # First dense layer\n",
        "    model.add(layers.Dense(units=100, activation='relu'))\n",
        "    # Result layer\n",
        "    model.add(layers.Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    # Compile model\n",
        "    model.compile(optimizer=\"adam\", metrics=[\"accuracy\"], loss=\"categorical_crossentropy\")\n",
        "\n",
        "    # Assign model to instance\n",
        "    self.neural_net = model\n",
        "\n",
        "    # Build an intermediate model to get the dense layer output\n",
        "    self.intermediate_model = Model(inputs=self.neural_net.input, outputs=self.neural_net.layers[7].output)\n",
        "\n",
        "    # Create a SVC model\n",
        "    self.svc = SVC()\n",
        "\n",
        "  def fit(self, X_train, Y_train):\n",
        "    # First we train the neural net to extract features from data\n",
        "    self.neural_net.fit(X_train, Y_train, epochs=100, batch_size=5)\n",
        "\n",
        "    # Pass to SVM to train\n",
        "    svc_x_train = self.intermediate_model.predict(X_train)\n",
        "    svc_y_train = np.argmax(Y_train.values, axis=1)\n",
        "\n",
        "    # Fit the SVM\n",
        "    self.svc.fit(svc_x_train, svc_y_train)\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    # First feed it through neural net\n",
        "    X_intermediate = self.intermediate_model.predict(X_test)\n",
        "    # Then we use svm to predict\n",
        "    X_predicted = self.svc.predict(X_intermediate)\n",
        "    # Return predicted\n",
        "    return X_predicted\n",
        "  \n",
        "  def accuracy(self, X_test, Y_test):\n",
        "    # Get the intermediate model result\n",
        "    svc_x_test = self.intermediate_model.predict(X_test)\n",
        "\n",
        "    # Map dummy array to label\n",
        "    svc_y_test = np.argmax(Y_test.values, axis=1)\n",
        "\n",
        "    # Get the SVC score\n",
        "    return self.svc.score(svc_x_test, svc_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC7YcUtXoyPM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b832237a-29fc-4ac1-fc11-de1fdac5e908"
      },
      "source": [
        "# Make sure that we add the chanel layer, in this case 1\n",
        "hybrid_X_train = X_train.values.reshape([-1, 16, 16, 1])\n",
        "hybrid_X_test = X_test.values.reshape([-1, 16, 16, 1])\n",
        "\n",
        "# Add padding to create a (32, 32, 1) image\n",
        "hybrid_X_train = np.pad(hybrid_X_train, ((0, 0), (6, 6), (6, 6), (0, 0)))\n",
        "hybrid_X_test = np.pad(hybrid_X_test, ((0, 0), (6, 6), (6, 6), (0, 0)))\n",
        "\n",
        "# Fit\n",
        "hybrid_model = HybridSVM()\n",
        "hybrid_model.fit(hybrid_X_train, Y_train)\n",
        "\n",
        "# Score\n",
        "print(f\"The accuracy for the Hybrid model is {hybrid_model.accuracy(hybrid_X_test, Y_test)}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 1.3863 - accuracy: 0.5251\n",
            "Epoch 2/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.4249 - accuracy: 0.8579\n",
            "Epoch 3/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.3040 - accuracy: 0.9105\n",
            "Epoch 4/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.1917 - accuracy: 0.9372\n",
            "Epoch 5/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.1745 - accuracy: 0.9419\n",
            "Epoch 6/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.1522 - accuracy: 0.9451\n",
            "Epoch 7/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0934 - accuracy: 0.9686\n",
            "Epoch 8/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.1179 - accuracy: 0.9568\n",
            "Epoch 9/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0904 - accuracy: 0.9655\n",
            "Epoch 10/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0933 - accuracy: 0.9710\n",
            "Epoch 11/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0760 - accuracy: 0.9741\n",
            "Epoch 12/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0542 - accuracy: 0.9796\n",
            "Epoch 13/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0846 - accuracy: 0.9694\n",
            "Epoch 14/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0646 - accuracy: 0.9780\n",
            "Epoch 15/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0595 - accuracy: 0.9796\n",
            "Epoch 16/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0457 - accuracy: 0.9804\n",
            "Epoch 17/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0511 - accuracy: 0.9827\n",
            "Epoch 18/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0547 - accuracy: 0.9843\n",
            "Epoch 19/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0478 - accuracy: 0.9812\n",
            "Epoch 20/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0635 - accuracy: 0.9796\n",
            "Epoch 21/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0470 - accuracy: 0.9843\n",
            "Epoch 22/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0512 - accuracy: 0.9859\n",
            "Epoch 23/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0356 - accuracy: 0.9867\n",
            "Epoch 24/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0482 - accuracy: 0.9780\n",
            "Epoch 25/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0353 - accuracy: 0.9843\n",
            "Epoch 26/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0473 - accuracy: 0.9835\n",
            "Epoch 27/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0532 - accuracy: 0.9827\n",
            "Epoch 28/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0396 - accuracy: 0.9890\n",
            "Epoch 29/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0289 - accuracy: 0.9914\n",
            "Epoch 30/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0431 - accuracy: 0.9859\n",
            "Epoch 31/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0318 - accuracy: 0.9906\n",
            "Epoch 32/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0375 - accuracy: 0.9874\n",
            "Epoch 33/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0287 - accuracy: 0.9914\n",
            "Epoch 34/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0282 - accuracy: 0.9898\n",
            "Epoch 35/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0348 - accuracy: 0.9874\n",
            "Epoch 36/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0266 - accuracy: 0.9898\n",
            "Epoch 37/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0306 - accuracy: 0.9890\n",
            "Epoch 38/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0271 - accuracy: 0.9898\n",
            "Epoch 39/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0375 - accuracy: 0.9898\n",
            "Epoch 40/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0410 - accuracy: 0.9890\n",
            "Epoch 41/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9906\n",
            "Epoch 42/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0349 - accuracy: 0.9867\n",
            "Epoch 43/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0278 - accuracy: 0.9898\n",
            "Epoch 44/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0373 - accuracy: 0.9867\n",
            "Epoch 45/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0442 - accuracy: 0.9827\n",
            "Epoch 46/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0182 - accuracy: 0.9929\n",
            "Epoch 47/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0388 - accuracy: 0.9867\n",
            "Epoch 48/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0451 - accuracy: 0.9882\n",
            "Epoch 49/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0288 - accuracy: 0.9882\n",
            "Epoch 50/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0370 - accuracy: 0.9882\n",
            "Epoch 51/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0231 - accuracy: 0.9929\n",
            "Epoch 52/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0289 - accuracy: 0.9914\n",
            "Epoch 53/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0308 - accuracy: 0.9929\n",
            "Epoch 54/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0224 - accuracy: 0.9922\n",
            "Epoch 55/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0442 - accuracy: 0.9843\n",
            "Epoch 56/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0203 - accuracy: 0.9937\n",
            "Epoch 57/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0271 - accuracy: 0.9929\n",
            "Epoch 58/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0262 - accuracy: 0.9922\n",
            "Epoch 59/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0158 - accuracy: 0.9937\n",
            "Epoch 60/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0119 - accuracy: 0.9945\n",
            "Epoch 61/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0190 - accuracy: 0.9945\n",
            "Epoch 62/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0452 - accuracy: 0.9859\n",
            "Epoch 63/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0109 - accuracy: 0.9953\n",
            "Epoch 64/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0236 - accuracy: 0.9906\n",
            "Epoch 65/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0407 - accuracy: 0.9859\n",
            "Epoch 66/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0375 - accuracy: 0.9882\n",
            "Epoch 67/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0372 - accuracy: 0.9882\n",
            "Epoch 68/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0513 - accuracy: 0.9890\n",
            "Epoch 69/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0359 - accuracy: 0.9898\n",
            "Epoch 70/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0348 - accuracy: 0.9922\n",
            "Epoch 71/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0225 - accuracy: 0.9937\n",
            "Epoch 72/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0255 - accuracy: 0.9922\n",
            "Epoch 73/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0377 - accuracy: 0.9898\n",
            "Epoch 74/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0146 - accuracy: 0.9953\n",
            "Epoch 75/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0249 - accuracy: 0.9937\n",
            "Epoch 76/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0095 - accuracy: 0.9969\n",
            "Epoch 77/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0205 - accuracy: 0.9929\n",
            "Epoch 78/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0483 - accuracy: 0.9898\n",
            "Epoch 79/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0206 - accuracy: 0.9937\n",
            "Epoch 80/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0315 - accuracy: 0.9922\n",
            "Epoch 81/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0221 - accuracy: 0.9937\n",
            "Epoch 82/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0097 - accuracy: 0.9976\n",
            "Epoch 83/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0078 - accuracy: 0.9976\n",
            "Epoch 84/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0163 - accuracy: 0.9961\n",
            "Epoch 85/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0296 - accuracy: 0.9929\n",
            "Epoch 86/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0197 - accuracy: 0.9945\n",
            "Epoch 87/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0203 - accuracy: 0.9969\n",
            "Epoch 88/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0082 - accuracy: 0.9953\n",
            "Epoch 89/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0315 - accuracy: 0.9906\n",
            "Epoch 90/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9976\n",
            "Epoch 91/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0280 - accuracy: 0.9929\n",
            "Epoch 92/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0195 - accuracy: 0.9914\n",
            "Epoch 93/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0408 - accuracy: 0.9937\n",
            "Epoch 94/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0139 - accuracy: 0.9953\n",
            "Epoch 95/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0223 - accuracy: 0.9961\n",
            "Epoch 96/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0458 - accuracy: 0.9890\n",
            "Epoch 97/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0401 - accuracy: 0.9906\n",
            "Epoch 98/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0203 - accuracy: 0.9929\n",
            "Epoch 99/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0090 - accuracy: 0.9961\n",
            "Epoch 100/100\n",
            "1274/1274 [==============================] - 2s 2ms/step - loss: 0.0313 - accuracy: 0.9906\n",
            "The accuracy for the Hybrid model is 0.9905956112852664\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGaYjZygXxrj",
        "colab_type": "text"
      },
      "source": [
        "# Independence Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsJRZ7kjz9sL",
        "colab_type": "text"
      },
      "source": [
        "The independent evaluation dataset is created by writing the number on a paper sheet, cutting them using a image processing program and then scalling them to get 16x16 pixel binary images.\n",
        "\n",
        "The images are then flatten into 256-element arrays and then unified to form a numpy array which is saved as created.data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wngXnwdHYQPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Open dataset\n",
        "test_digits_url = \"https://raw.githubusercontent.com/PhatTranSon/MachineLearningAssignment/master/independent.data\"\n",
        "test_digits = pd.read_csv(test_digits_url, delimiter = \" \", header = None)\n",
        "\n",
        "# Define X and Y\n",
        "independent_X = test_digits.iloc[:, :256].values\n",
        "independent_Y = test_digits.iloc[:, 256:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH3Hxd5xZUEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "14b8a241-af77-453e-c38a-678051fcf0c9"
      },
      "source": [
        "# Reshape the input\n",
        "hybrid_X = independent_X.reshape([-1, 16, 16, 1])\n",
        "hybrid_X = np.pad(hybrid_X, ((0, 0), (6, 6), (6, 6), (0, 0)))\n",
        "# Fit the model\n",
        "hybrid_score = hybrid_model.accuracy(hybrid_X, independent_Y)\n",
        "# Print score\n",
        "print(f\"The independent evaluation accuracy for hybrid model is {hybrid_score}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The independent evaluation accuracy for hybrid model is 0.7916666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHm6ugJ6csla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "cd4517d2-e773-46b4-c456-39a016357993"
      },
      "source": [
        "# Reshape the input\n",
        "lenet_X = independent_X.reshape([-1, 16, 16, 1])\n",
        "lenet_X = np.pad(lenet_X, ((0, 0), (8, 8), (8, 8), (0, 0)))\n",
        "\n",
        "# Fit the model\n",
        "lenet_score = lenet_model.accuracy(lenet_X, independent_Y)\n",
        "\n",
        "# Print score\n",
        "print(f\"The independent evaluation accuracy for LeNet model is {lenet_score}\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 0s 309us/step\n",
            "The independent evaluation accuracy for LeNet model is 0.7788461446762085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SPxJtPeE9-e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "164e9725-6977-472d-ac79-cb538c5d995d"
      },
      "source": [
        "# KNN model\n",
        "knn_score = knn_model.accuracy(independent_X, independent_Y)\n",
        "print(f\"The independent evaluation accuracy for KNN model is {knn_score}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The independent evaluation accuracy for KNN model is 0.46794871794871795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QoqqDsEFQL7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "d854a53b-ab06-4607-e7cd-32792706485e"
      },
      "source": [
        "# SVC model\n",
        "svc_independent_X = independent_X\n",
        "svc_independent_Y = np.argmax(independent_Y.values, axis=1)\n",
        "\n",
        "svc_score = svc_model.accuracy(svc_independent_X, svc_independent_Y)\n",
        "print(f\"The independent evaluation accuracy for SVM model is {svc_score}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The independent evaluation accuracy for SVM model is 0.47435897435897434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZCAK6Uihg0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "bea866b0-62fa-45a2-f7b4-4e68afd9a924"
      },
      "source": [
        "# Define X and Y\n",
        "lrc_independent_X = test_digits.iloc[:, :256]\n",
        "lrc_independent_Y_ = test_digits.iloc[:, 256:]\n",
        "index, lrc_independent_y = index,labels = np.where(independent_Y.values == 1)\n",
        "lrc_y_pre = LRC().predict(lrc_X_train, lrc_Y_train, lrc_independent_X)\n",
        "\n",
        "print(\"The accuracy of the Linear Regression Classification model on independent dataset:\",accuracy_score(lrc_independent_y, lrc_y_pre))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of the Linear Regression Classification model on independent dataset: 0.5865384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsZzA-vFB0uh",
        "colab_type": "text"
      },
      "source": [
        "# Inaccurate prediction analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBG2Pjn81WfF",
        "colab_type": "text"
      },
      "source": [
        "In this section, we view the images that were inaccurately classfied by two top models: LeNet inspired and Hybrid CNN-SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDTFNxRUCBMY",
        "colab_type": "text"
      },
      "source": [
        "## a) LeNet-inspired model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYbRl07RCORU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict test set\n",
        "lenet_predicted_Y = np.argmax(lenet_model.predict(lenet_X_test), axis=1)\n",
        "lenet_actual_Y = np.argmax(Y_test.values, axis=1)\n",
        "\n",
        "# Get the wrong position\n",
        "lenet_wrong_positions = np.nonzero(lenet_predicted_Y != lenet_actual_Y)[0]\n",
        "\n",
        "# Get the wrong digits\n",
        "lenet_Y_actual_label = lenet_actual_Y[lenet_wrong_positions]\n",
        "lenet_Y_predicted_label = lenet_predicted_Y[lenet_wrong_positions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSJ0Vp6xG3rs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "3ede22b2-a00c-4681-ff76-ab6d46f11d16"
      },
      "source": [
        "# Plot\n",
        "num_row = 1\n",
        "num_col = lenet_wrong_positions.shape[0]\n",
        "\n",
        "# Create figure\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(2*num_col,2*num_row))\n",
        "for i in range(num_col):\n",
        "    ax = axes[i]\n",
        "    ax.imshow(X_test.values[lenet_wrong_positions[i], :].reshape(16, 16), cmap='gray')\n",
        "    ax.set_title('Actual: {} Predicted: {}'.format(lenet_Y_actual_label[i], lenet_Y_predicted_label[i]))\n",
        "\n",
        "# Show \n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lenet_wrong2.png\")\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x144 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7UZ_CHoCFfb",
        "colab_type": "text"
      },
      "source": [
        "## b) Hyrbid model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLB4s0M0CLe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predictions\n",
        "hybrid_predicted_Y = hybrid_model.predict(hybrid_X_test)\n",
        "hybrid_actual_Y = np.argmax(Y_test.values, axis=1)\n",
        "\n",
        "# Get the wrong position\n",
        "hybrid_wrong_positions = np.nonzero(hybrid_predicted_Y != hybrid_actual_Y)[0]\n",
        "\n",
        "# Get the wrong digits\n",
        "hybrid_X_wrong = X_test.values[hybrid_wrong_positions, :]\n",
        "hybrid_Y_actual_label = hybrid_actual_Y[hybrid_wrong_positions]\n",
        "hybrid_Y_predicted_label = hybrid_predicted_Y[hybrid_wrong_positions]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5dGRrStUkzo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "1b60544f-0431-40e6-f17c-1d7d3cc2cf38"
      },
      "source": [
        "# Plot\n",
        "num_row = 1\n",
        "num_col = hybrid_wrong_positions.shape[0]\n",
        "\n",
        "# Create figure\n",
        "fig, axes = plt.subplots(num_row, num_col, figsize=(2*num_col,2*num_row))\n",
        "for i in range(num_col):\n",
        "    ax = axes[i]\n",
        "    ax.imshow(X_test.values[hybrid_wrong_positions[i], :].reshape(16, 16), cmap='gray')\n",
        "    ax.set_title('Actual: {} Predicted: {}'.format(hybrid_Y_actual_label[i], hybrid_Y_predicted_label[i]))\n",
        "\n",
        "# Show \n",
        "plt.tight_layout()\n",
        "plt.savefig(\"hybrid_wrong.png\")\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x144 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMTo7DvI3NQc",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning on Independent Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lgt8uz33too",
        "colab_type": "text"
      },
      "source": [
        "In this approach, we train the CNN using training data, freeze its weights and proceed to train the SVM classifier using train data from the independent set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0dVArS1-ecc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HybridSVMTransferV2:\n",
        "  def __init__(self, pretrained):\n",
        "    # Set the pre trained model\n",
        "    self.pretrained_model = pretrained\n",
        "\n",
        "  def fit(self, X_train, Y_train):\n",
        "    # We freeze the CNN weights -> We fit only the SVM classifier\n",
        "    svc_x_train = self.pretrained_model.intermediate_model.predict(X_train)\n",
        "    svc_y_train = np.argmax(Y_train.values, axis=1)\n",
        "    self.pretrained_model.svc.fit(svc_x_train, svc_y_train)\n",
        "\n",
        "  def accuracy(self, X_test, Y_test):\n",
        "    # Get the intermediate model result\n",
        "    svc_x_test = self.pretrained_model.intermediate_model.predict(X_test)\n",
        "    # Map dummy array to label\n",
        "    svc_y_test = np.argmax(Y_test.values, axis=1)\n",
        "    # Get the SVC score\n",
        "    return self.pretrained_model.svc.score(svc_x_test, svc_y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2-1vOHn_mfv",
        "colab_type": "code",
        "outputId": "8cff8f31-7638-4ba2-c123-5820e3b19d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Split train and test set for independent set\n",
        "index, labels = np.where(independent_Y.values == 1)\n",
        "independent_X_train, independent_X_test, independent_Y_train, independent_Y_test = train_test_split(independent_X, independent_Y, stratify = labels, test_size=0.2, random_state=0)\n",
        "\n",
        "# Add padding\n",
        "# Make sure that we add the chanel layer, in this case 1\n",
        "target_X_train = independent_X_train.reshape([-1, 16, 16, 1])\n",
        "target_X_test = independent_X_test.reshape([-1, 16, 16, 1])\n",
        "\n",
        "# Add padding to create a (32, 32, 1) image\n",
        "target_X_train = np.pad(target_X_train, ((0, 0), (6, 6), (6, 6), (0, 0)))\n",
        "target_X_test = np.pad(target_X_test, ((0, 0), (6, 6), (6, 6), (0, 0)))\n",
        "\n",
        "# Create model and train\n",
        "transfer_model = HybridSVMTransferV2(hybrid_model)\n",
        "transfer_model.fit(target_X_train, independent_Y_train)\n",
        "\n",
        "# Display accuracy\n",
        "print(f\"The accuracy of Transfer Learning model is {transfer_model.accuracy(target_X_test, independent_Y_test)}\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of Transfer Learning model is 0.9523809523809523\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}